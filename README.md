
### Work IN Progress Project (Active Project)

Building Neural Networks from scratch using only NUMPY

This project is a work-in-progress implementation of a neural network from scratch. The goal is to build a functional neural network library using only NumPy, for educational purposes.

#### Current Features:
*   **Dense Layer**: A fully connected layer with forward and backward propagation.
*   **Activation Functions**: ReLU, Sigmoid, Softmax, and Linear activations with backward pass.
*   **Loss Functions**: MSE, MAE, SSE, Categorical Cross-Entropy, and Sparse Cross-Entropy.
*   **Backpropagation**: Full implementation of the backward pass.

#### Future Goals:
*   Create a `Model` class to manage layers and the training process.
*   Implement optimizers (e.g., Adam, SGD).
*   Add different layer types (e.g., convolutional).
